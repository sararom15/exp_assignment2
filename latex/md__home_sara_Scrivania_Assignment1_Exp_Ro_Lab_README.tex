\section*{Behavioral Architecture}

Assuming a Robot, simulating a pet, that interacts with a human and moves in a discrete 2D environment. The robot may have three behaviors \+: normal (in which it moves randomly), sleep (in which it gets the home position, sleeps for a time and returns in normal behavior) and play (in which it goes in person location, waits for a poiting gesture, goes in the pointed location, comes back to the person and waits for the next pointing gestures. After some time it returns to the normal behavior). The human can interact by pointing gestures and speech.

\subsection*{R\+OS Architecture}

The system is composed by 3 nodes\+:\char`\"{}\+Commander\char`\"{} node, \char`\"{}state\+\_\+machine\char`\"{} node and \char`\"{}\+Display\char`\"{} node, and a Launch file. The rqt\+\_\+graph is showed.

 

\subsubsection*{Commander node}

The node simulates user action. Firstly it chooses randomly what the robot must perform\+: sleep or play. The command (std\+\_\+msgs/\+String) is published on a Topic (\char`\"{}/\+Command\char`\"{}). In case the play behavior is selected, the node generates randomly the location of the user and the Pointing Gesture. These poses (geometry\+\_\+msgs/\+Point) are published on two topics (\char`\"{}/\+Person\+Position\char`\"{} and \char`\"{}/\+Pointing\+Gesture\char`\"{}).

\subsubsection*{State machine node}

The node implements a state machine in which the three possible behaviors are defined.

 

The state machine starts with a Normal behavior state, and it can transit to sleep state or to play state, or it can keep a normal state. The command to switch to another state is received by \char`\"{}\+Commander\char`\"{} node by the topic \char`\"{}/\+Command\char`\"{}. When it is in a Play state or in a Sleep state, it can just go back in the normal state. The R\+OS message geometry\+\_\+msgs/\+Point is used to rapresent the 2D robot\textquotesingle{}s position (leaving z component always equal to 0). The target position belongs exclusively to the map (11x11 grid). In the normal state, they are generated by \char`\"{}\+Generate\+Random\+Position\char`\"{} function; in the play state, the person position and pointing gesture are received by \char`\"{}\+Commander\char`\"{} node through two topics; while in the sleep state the home position is defined (1,1). For each state, the target positions are sent to the \char`\"{}display\char`\"{} node, publishing them on \char`\"{}\+New\+Target\+Position\char`\"{} topic. When this happens, the system waits for a default time (4 seconds) until the robot reaches the desired pose. This means that further targets has not been accepted while the robot is moving.

\subsubsection*{Display node}

The node is a simple simulator; it subscribes to a \char`\"{}new\+Target\+Position\char`\"{} topic and wait for a message. When the target is received, it prints on terminal what the robot is doing and the behavior state.

\subsection*{Installation}

The first thing to do, after having cloned the repository in the Ros workspace, is to build the package, using the following commands in the shell\+: \begin{DoxyVerb}```
cd "yourWorkspace"_ws
catkin_make

```
\end{DoxyVerb}
 To run the system\+: \begin{DoxyVerb}```
roslaunch assignment1_ExRoLab ass1.launch

```
\end{DoxyVerb}
 In another terminal run\+: \begin{DoxyVerb}```
rosrun assignment1_ExRoLab Commander.py 

```
\end{DoxyVerb}


To visualize the smach viewer\+: \begin{DoxyVerb}```
rosrun smach_viewer smach_viewer.py

```
\end{DoxyVerb}


\subsection*{Working Hypothesis}

The assumptions are\+: 1) When it starts, the normal state preempts other states. 2) From the normal behavior, the robot can play or sleep or stay in normal state yet. 3) The command to go to sleep or play is received by the Commander node. 4) From the play state, as well as from the sleep state, the robot can only go to the normal state. 5) The random position in the normal state is defined by \char`\"{}\+Generate\+Random\+Position\char`\"{} function. 6) The home position is fixed (1,1,0). 7) The person location and the pointing gesture are received by the Commander node. 8) During the execution of one state, after giving a target, the robot waits for a while (predefined time).

\subsection*{System\textquotesingle{}s features}

The sys can show on the terminal what the robot is doing and the what the behavior\textquotesingle{}s state is executing.

\subsection*{System\textquotesingle{}s Limitations}

The user actions is randomly defined by the system, and there exists neither a real relationship with the user nor a real pointing gesture. The robot has not a velocity to get him desired target position, and there is not a real simulator to view if the target is achieved.

\subsection*{Possible technical Improvements}

A possible technical improvements may be\+: 1) create a real interaction with the user; 2) Implement a real velocity to change the odometry of the robot; 4) Implement a simulator (like Gazebo, Stage, Turtlesim,...).

\subsection*{Author}

Sara Romano -\/ \href{mailto:sara.romano.15@gmail.com}{\tt sara.\+romano.\+15@gmail.\+com} 